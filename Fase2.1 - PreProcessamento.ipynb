{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68f0d141",
   "metadata": {},
   "source": [
    "### Importação das Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105b7d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "#Pacotes Estatísticos\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "#ML\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba709b3",
   "metadata": {},
   "source": [
    "### Variáveis de Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03f72df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_origem = \"C:/Lab Transp/Dados Processados/\"\n",
    "local_destino = \"C:/Lab Transp/Dados Processados/\"\n",
    "\n",
    "data_inicio = \"2014-01-01\"\n",
    "data_fim = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b55fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Manipulacao_Arquivos:\n",
    "        \n",
    "    def abrir_arquivo(self, caminho, arquivo):\n",
    "        try:\n",
    "            df = pd.read_csv(caminho + \"\\\\\" + arquivo + \".csv\", encoding=\"latin-1\", decimal=\".\",  low_memory=False)     \n",
    "            return df\n",
    "        except:\n",
    "            try:\n",
    "                df = pd.read_csv(caminho + \"\\\\\" + arquivo + \".csv\", encoding=\"latin-1\", sep=\";\", decimal=\".\",  low_memory=False)\n",
    "                return df\n",
    "            except Exception as error:\n",
    "                print('Erro ao carregar arquivo: ' + repr(error))\n",
    "                return None\n",
    "    \n",
    "    \n",
    "    def criar_arquivo_primario(self, caminho, arquivo_blihetagem = \"BD_Bilhetagem\", arquivo_linhas = \"BD_Linhas_Geoespacial\"):\n",
    "        #Abro os arquivos de origem\n",
    "        df_bilhetagem = self.abrir_arquivo(local_origem, \"BD_Bilhetagem\")\n",
    "        df_linhas = self.abrir_arquivo(local_origem, \"BD_Linhas_Geoespacial\")\n",
    "        \n",
    "        df_bilhetagem['LINHA_TRATADA'] = df_bilhetagem['LINHA'].str.split('-').str[0]\n",
    "        df_bilhetagem['LINHA_TRATADA'] = df_bilhetagem['LINHA_TRATADA'].astype(str)\n",
    "        df_bilhetagem['LINHA_TRATADA'] = df_bilhetagem['LINHA_TRATADA'].apply(lambda x: x.strip())        \n",
    "\n",
    "        df_final = df_bilhetagem.merge(df_linhas[['ln_nome_tp', \n",
    "                                                  'ln_empresa_tp',\n",
    "                                                  'ln_codigo_tp',\n",
    "                                                  'pt_nome_tp',\n",
    "                                                  'ds_subpref_tp', \n",
    "                                                  'latitude_longitude_tp',           \n",
    "                                                  'pt_nome_ts',\n",
    "                                                  'ds_subpref_ts', \n",
    "                                                  'latitude_longitude_ts']],\n",
    "                                           left_on=\"LINHA_TRATADA\",\n",
    "                                           right_on=\"ln_codigo_tp\",\n",
    "                                           how=\"left\")\n",
    "        \n",
    "        #Tratar colunas de texto\n",
    "        df_final = self.tratar_colunas_strings(df_final, ['EMPRESA'])        \n",
    "        \n",
    "        #Tratar colunas de data\n",
    "        df_final = self.tratar_colunas_datas(df_final, ['DATA'])\n",
    "        \n",
    "        df_final[\"ANO\"] = df_final[\"DATA\"].dt.year\n",
    "        df_final[\"ANO\"] = df_final[\"ANO\"].fillna(0).astype(int)        \n",
    "        \n",
    "        df_final[\"MES\"] = df_final[\"DATA\"].dt.month\n",
    "        df_final[\"MES\"] = df_final[\"MES\"].fillna(0).astype(int)\n",
    "        \n",
    "        df_final[\"DIA\"] = df_final[\"DATA\"].dt.day\n",
    "        df_final[\"DIA\"] = df_final[\"DIA\"].fillna(0).astype(int)\n",
    "        \n",
    "        \n",
    "        #Filtrar pelo data de corte\n",
    "        df_final = df_final[df_final['DATA']>=data_inicio]\n",
    "        \n",
    "        \n",
    "        #Tratar colunas numéricas\n",
    "        df_final = self.tratar_colunas_numericas(df_final, ['PASSAGEIROS_GRATUIDADE', 'PASSAGEIROS_GRATUIDADE_ESTUDANTE', 'PASSAGEIROS_PAGANTES',\n",
    "                                                            'PASSAGEIROS_PAGANTES_BU_COMUM', 'PASSAGEIROS_PAGANTES_BU_COMUM_MENSAL', 'PASSAGEIROS_PAGANTES_BU_ESTUDANTES',\n",
    "                                                            'PASSAGEIROS_PAGANTES_BU_ESTUDANTES_MENSAL', 'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP', 'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP_MENSAL',\n",
    "                                                            'PASSAGEIROS_PAGANTES_DINHEIRO', 'PASSAGEIROS_PAGANTES_ESTUDANTES', 'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_METRO_CPTM',\n",
    "                                                            'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_ONIBUS', 'TOTAL'])\n",
    "        \n",
    "        \n",
    "        #Consolidação dos Tipos de Passageiros\n",
    "        df_final['VOLUME_TOTAL_PASSAGEIROS_PAGANTES'] = df_final['PASSAGEIROS_PAGANTES']        \n",
    "        df_final['PAGANTES_DINHEIRO'] = df_final['PASSAGEIROS_PAGANTES_DINHEIRO']\n",
    "        df_final['VOLUME_TOTAL_PASSAGEIROS_GRATUIDADE'] = df_final['PASSAGEIROS_GRATUIDADE'] + df_final['PASSAGEIROS_GRATUIDADE_ESTUDANTE']\n",
    "        df_final['BU_COMUM'] = df_final['PASSAGEIROS_PAGANTES_BU_COMUM'] + df_final['PASSAGEIROS_PAGANTES_BU_COMUM_MENSAL']\n",
    "        df_final['BU_VALE_TRANSPORTE'] = df_final['PASSAGEIROS_PAGANTES_BU_VALE_TRANSP'] + df_final['PASSAGEIROS_PAGANTES_BU_VALE_TRANSP_MENSAL']\n",
    "        df_final['INTEGRACAO'] = df_final['PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_METRO_CPTM'] + df_final['PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_ONIBUS']\n",
    "        df_final['BU_ESTUDANTE'] = df_final['PASSAGEIROS_PAGANTES_BU_ESTUDANTES'] + df_final['PASSAGEIROS_PAGANTES_BU_ESTUDANTES_MENSAL'] + df_final['PASSAGEIROS_PAGANTES_ESTUDANTES']\n",
    "        \n",
    "        #Para fins deste estudo, estamos usando essas variáveis\n",
    "        df_final['VOLUME_TOTAL_PASSAGEIROS_BU_VT'] = df_final['BU_COMUM'] + df_final['BU_VALE_TRANSPORTE']        \n",
    "        df_final['VOLUME_TOTAL_PASSAGEIROS_BU_VT_DIN'] = df_final['VOLUME_TOTAL_PASSAGEIROS_BU_VT'] + df_final['PAGANTES_DINHEIRO']\n",
    "        \n",
    "        \n",
    "        #Depois das todas as somas, eu volto os zeros para NAN para tratá-los mais facilmente depois\n",
    "        df_final['VOLUME_TOTAL_PASSAGEIROS_BU_VT'] = df_final['VOLUME_TOTAL_PASSAGEIROS_BU_VT'].replace(0, np.nan)\n",
    "        df_final['VOLUME_TOTAL_PASSAGEIROS_BU_VT_DIN'] = df_final['VOLUME_TOTAL_PASSAGEIROS_BU_VT_DIN'].replace(0, np.nan)\n",
    "        \n",
    "        '''\n",
    "        A especificação é que o volume de interesse fosse BU + VT.\n",
    "        O Problema é que nem sempre essas colunas retornam preechidas corretamente\n",
    "        A sugestão é utilizar a 'PASSAGEIROS_PAGANTES'\n",
    "        '''\n",
    "        #df_final['VOLUME_TOTAL_PASSAGEIROS_INTERESSE'] = df_final['BU_COMUM'] + df_final['BU_VALE_TRANSPORTE'] \n",
    "\n",
    "        '''\n",
    "        Em alguns casos, apesar da linha ter o mesmo nome completo, não a encontro via o nome tratado. \n",
    "        Assim, crio um dicionário por Linha_Completa e a Sub_Prefeitura mapeada, excluindo os que ficaram ausentes\n",
    "        Então, remapeio a coluna Sub_Prefeitura com os valores preenchidos\n",
    "        '''        \n",
    "        \n",
    "        #Crio o dicionário\n",
    "        ref_sub = df_final[['LINHA', 'ds_subpref_tp']].drop_duplicates()\n",
    "        ref_sub = ref_sub[np.logical_not(ref_sub['ds_subpref_tp'].isna())]\n",
    "        ref_sub_dict = dict(zip(ref_sub.LINHA, ref_sub.ds_subpref_tp))\n",
    "\n",
    "        #Substituo os valores\n",
    "        df_final['ds_subpref_tp'] = df_final['LINHA'].map(ref_sub_dict)\n",
    "        \n",
    "        ref_sub= None\n",
    "        ref_sub_dict= None\n",
    "        \n",
    "            \n",
    "        #Carrego a Zona da Sub-Prefeitura do Ponto Inicial\n",
    "        with open(local_origem + \"\\zonas_sub_pref.json\") as dic_zonas:\n",
    "            dict_zonas_sub_pref = json.load(dic_zonas)        \n",
    "            \n",
    "        df_final['Zona'] = df_final['ds_subpref_tp'].map(dict_zonas_sub_pref)\n",
    "        \n",
    "        \n",
    "        #Renomeio as colunas\n",
    "        df_final.rename(columns={'NOME_ARQUIVO' : 'Nome_Arquivo', \n",
    "                                 'DATA' : 'Data', \n",
    "                                 'AREA' : 'Area', \n",
    "                                 'EMPRESA' : 'Empresa', \n",
    "                                 'LINHA' : 'Linha_Completa', \n",
    "                                 'TIPO' : 'Tipo', \n",
    "                                 'TOTAL' : 'Total', \n",
    "                                 'ANO' : 'Ano', \n",
    "                                 'MES' : 'Mes', \n",
    "                                 'DIA' : 'Dia', \n",
    "                                 'LINHA_TRATADA' : 'Linha',                                 \n",
    "                                 'ds_subpref_tp' : 'Sub_Prefeitura',\n",
    "                                 'pt_nome_tp'    : 'Nome_Ponto_Inicial',\n",
    "                                 'pt_nome_ts'    : 'Nome_Ponto_Final',\n",
    "                                 'latitude_longitude_tp' : 'Lat_Long_Ponto_Inicial',\n",
    "                                 'latitude_longitude_ts' : 'Lat_Long_Ponto_Final',\n",
    "                                 'VOLUME_TOTAL_PASSAGEIROS_PAGANTES' : 'Volume_Passageiros_Pagantes', \n",
    "                                 'PAGANTES_DINHEIRO' : 'Volume_Pagantes_Dinheiro', \n",
    "                                 'VOLUME_TOTAL_PASSAGEIROS_GRATUIDADE' : 'Volume_Passageiros_Gratuidade', \n",
    "                                 'BU_COMUM' : 'Volume_BU_Comum', \n",
    "                                 'BU_VALE_TRANSPORTE' : 'Volume_BU_Vale_Transporte', \n",
    "                                 'INTEGRACAO' : 'Volume_Integracao', \n",
    "                                 'BU_ESTUDANTE' : 'Volume_BU_Estudante', \n",
    "                                 'VOLUME_TOTAL_PASSAGEIROS_BU_VT' : 'Volume_Passageiros_BU_VT', \n",
    "                                 'VOLUME_TOTAL_PASSAGEIROS_BU_VT_DIN' : 'Volume_Passageiros_BU_VT_DIN'}, inplace=True)          \n",
    "\n",
    "        \n",
    "        perc_encontrados = len(np.unique(df_final[df_final['ln_codigo_tp'].notnull()]['ln_nome_tp']))/len(np.unique(df_final['Linha']))\n",
    "        print(f'{perc_encontrados: .1%} das linhas em Bilhetagem encontrados no cadastro georeferencial de linhas')\n",
    "    \n",
    "        #Depois de consolidar os valores, dropo as colunas        \n",
    "        df_final.drop(columns=['ds_subpref_ts', 'ln_nome_tp', 'ln_empresa_tp', 'ln_codigo_tp', 'PASSAGEIROS_GRATUIDADE', 'PASSAGEIROS_GRATUIDADE_ESTUDANTE', 'PASSAGEIROS_PAGANTES', 'PASSAGEIROS_PAGANTES_BU_COMUM',\n",
    "                               'PASSAGEIROS_PAGANTES_BU_COMUM_MENSAL', 'PASSAGEIROS_PAGANTES_BU_ESTUDANTES', 'PASSAGEIROS_PAGANTES_BU_ESTUDANTES_MENSAL',\n",
    "                               'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP', 'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP_MENSAL', 'PASSAGEIROS_PAGANTES_DINHEIRO', 'PASSAGEIROS_PAGANTES_ESTUDANTES',\n",
    "                               'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_METRO_CPTM', 'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_ONIBUS'], inplace=True)\n",
    "                    \n",
    "        return df_final\n",
    "    \n",
    "    def tratar_colunas_strings(self, df, colunas):\n",
    "        \n",
    "        for col in colunas:\n",
    "            df[col] = df[col].astype(str)\n",
    "            df[col] = df[col].apply(lambda x: x.strip().upper())\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def tratar_colunas_datas(self, df, colunas):\n",
    "        for col in colunas:\n",
    "            df[col] = df[col].astype(str)\n",
    "            df[col] = df[col].apply(lambda x: x.strip(\" 00:00:00\"))\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def tratar_colunas_numericas(self, df, colunas):\n",
    "        for col in colunas:\n",
    "            df[col] = df[col].astype(float)\n",
    "            df[col] = df[col].fillna(0)            \n",
    "        return df\n",
    "                \n",
    "    def salvar_arquivo(self, caminho, df, arquivo):\n",
    "        df.to_csv(caminho + \"\\\\\" + arquivo + \".csv\" , index=False, encoding=\"latin-1\", decimal=\",\")        \n",
    "        return None\n",
    "    \n",
    "    def lista_agregadora(self, df, coluna=\"Sub_Prefeitura\"):\n",
    "        df[coluna] = df[coluna].astype(str)\n",
    "        return np.unique(df[coluna].to_numpy())\n",
    "    \n",
    "    \n",
    "    def selecao_linhas(self, df, apenas_nao_terminais, limiar_dias, manter_apenas_modalidades_pagamentos_primarias):\n",
    "        #Manteho apenas as linhas que não terminam em terminais\n",
    "        if apenas_nao_terminais==True:\n",
    "            df = df[np.logical_not(df['Nome_Ponto_Inicial'].str.contains('TERM'))].reset_index(drop=True)\n",
    "            df = df[np.logical_not(df['Nome_Ponto_Final'].str.contains('TERM'))].reset_index(drop=True)\n",
    "\n",
    "        #Removo as linhas com registros abaixo do limiar de dias definido\n",
    "        g_amostra = df[['Linha']].groupby('Linha').size().reset_index()\n",
    "        linhas_selecionadas = g_amostra[g_amostra[0]>=limiar_dias]['Linha']\n",
    "        df[df['Linha'].isin(linhas_selecionadas)].reset_index(drop=True)   \n",
    "\n",
    "\n",
    "        if manter_apenas_modalidades_pagamentos_primarias==True:\n",
    "            df.dropna(subset=['Volume_Passageiros_BU_VT'], inplace=True)\n",
    "        \n",
    "        return df\n",
    "            \n",
    "    def definicao_linhas_maes(self, df):\n",
    "        df_linhas_sub_pref = df[['Sub_Prefeitura', 'Zona', 'Data', 'Linha', 'Nome_Ponto_Inicial', 'Nome_Ponto_Final']].groupby(['Zona', 'Sub_Prefeitura', 'Linha',  'Nome_Ponto_Inicial', 'Nome_Ponto_Final'], as_index=False).count().sort_values(by=['Zona', 'Sub_Prefeitura','Data'], ascending=True)\n",
    "\n",
    "        df_linha_mae = df_linhas_sub_pref.groupby(by=['Zona', 'Sub_Prefeitura'], \n",
    "                                                  as_index=False, \n",
    "                                                  sort=False).apply(lambda x: x.loc[x[\"Data\"].idxmax()])\n",
    "        \n",
    "        return df_linhas_sub_pref, df_linha_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c6095de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessamento:\n",
    "    \n",
    "    def tratar_dados_ausentes_(self, df, coluna=\"Volume_Passageiros_BU_VT_DIN\", grupo=\"Linha\", metodo=\"remover\"):\n",
    "\n",
    "        if metodo.lower()==\"remover\":\n",
    "            df = df.dropna(subset=[coluna])\n",
    "            \n",
    "        elif metodo.lower()==\"zero\":\n",
    "            df[coluna] = df[coluna].fillna(0)\n",
    "                \n",
    "        elif metodo.lower()==\"média\":\n",
    "            df[coluna] = df[coluna].fillna(df.groupby(grupo)[coluna].transform('mean'))\n",
    "            \n",
    "        elif metodo.lower()==\"mediana\":\n",
    "            df[coluna] = df[coluna].fillna(df.groupby(grupo)[coluna].transform('median'))\n",
    "            \n",
    "        elif metodo.lower()==\"interpolação\":\n",
    "            #Quanto interpolamos, algumas colunas continuam com NaN. \n",
    "            #O ideal será chamar a função 'tratar_dados_ausentes' com um novo método            \n",
    "            df = df.groupby('Linha', as_index=False).apply(lambda group: group.interpolate(method='linear')).reset_index(drop=True)\n",
    "            \n",
    "        else:\n",
    "            print(\"ERRO: Método de tratamento não identificado...\")\n",
    "            print(\"Especifique um metódo dentre as opções: Remover, Zero, Média, Mediana ou Interpolação\")\n",
    "            print(\"O dataframe não foi alterado\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def corrigir_outliers(self, df, coluna=\"Volume_Passageiros_BU_VT_DIN\", metodo=\"interquartil\"):\n",
    "                \n",
    "        if metodo.lower()==\"interquartil\":\n",
    "            for i, linha in enumerate(np.unique(df['Linha'])):\n",
    "                \n",
    "                #Definição dos Quartis\n",
    "                Q1 = df_final[df_final['Linha']==linha]['Volume_Passageiros_BU_VT'].quantile(0.25)\n",
    "                Q3 = df_final[df_final['Linha']==linha]['Volume_Passageiros_BU_VT'].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "\n",
    "                #Diferença Interquartil\n",
    "                limite_inferior = Q1 - 1.5*IQR\n",
    "                limite_superior = Q3 + 1.5*IQR    \n",
    "\n",
    "                #Filtro dos valores limites\n",
    "                fora_limite_inferior = np.where((df_final['Linha']==linha) & (df_final['Volume_Passageiros_BU_VT'] <= limite_inferior))[0]\n",
    "                fora_limite_superior = np.where((df_final['Linha']==linha) & (df_final['Volume_Passageiros_BU_VT'] >= limite_superior))[0]\n",
    "\n",
    "                #Remoção dos Outliers\n",
    "                if i == 0:\n",
    "                    df_sem_outliers = df_final.drop(index=fora_limite_superior)\n",
    "                    df_sem_outliers = df_final.drop(index=fora_limite_inferior)\n",
    "                    df_sem_outliers.reset_index(drop=True, inplace=True)\n",
    "                else:\n",
    "                    df_sem_outliers = df_sem_outliers.drop(index=fora_limite_superior)\n",
    "                    df_sem_outliers = df_sem_outliers.drop(index=fora_limite_inferior)\n",
    "                    df_sem_outliers.reset_index(drop=True, inplace=True)\n",
    "                    \n",
    "        \n",
    "        elif metodo.lower()==\"zscore\":\n",
    "            z = np.abs(stats.zscore(df[coluna]))\n",
    "            \n",
    "            limite_z = 2\n",
    "            outlier_indices = np.where(z > limite_z)[0]\n",
    "            df_sem_outliers = df.drop(index=outlier_indices)\n",
    "            \n",
    "        else:\n",
    "            print(\"ERRO: Método de transformação não identificado...\")\n",
    "            print(\"Especifique um metódo dentre as opções: Log, Diferenciação, Pontencia, Raiz Qaudrada ou Box-Cox\")\n",
    "            print(\"O dataframe não foi alterado\")\n",
    "            \n",
    "        \n",
    "        return df_sem_outliers\n",
    "    \n",
    "    def transformacao_dados_(self, df, coluna=\"Volume_Passageiros_BU_VT_DIN\", grupo=\"LINHA_TRATADA\", metodo=\"nenhum\"):\n",
    "       \n",
    "        if metodo.lower()==\"log\":\n",
    "            df[coluna] = np.log(df[coluna])\n",
    "            \n",
    "        elif metodo.lower()==\"diferenciacao\":            \n",
    "            df[coluna+\"_diff\"] = df.groupby([grupo])[coluna].diff().fillna(0)\n",
    "            \n",
    "        elif metodo.lower()==\"potencia\":\n",
    "            df[coluna] = np.power(df[coluna], 2)\n",
    "            \n",
    "        elif metodo.lower()==\"raiz quadrada\":\n",
    "            df[coluna] = np.sqrt(df[coluna])\n",
    "                        \n",
    "        elif metodo.lower()==\"box cox\":\n",
    "            df[coluna] = scipy.stats.boxcox(df[coluna])[0]\n",
    "        \n",
    "        elif metodo.lower()==\"nenhum\":\n",
    "            print(\"O dataframe não foi alterado\")\n",
    "            \n",
    "        else:\n",
    "            print(\"ERRO: Método de transformação não identificado...\")\n",
    "            print(\"Especifique um metódo dentre as opções: Log, Diferenciação, Pontencia, Raiz Qaudrada ou Box-Cox\")\n",
    "            print(\"O dataframe não foi alterado\")\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def normalizacao_dados_(self, df, coluna=\"VOLUME_TOTAL_PASSAGEIROS\", metodo=\"Standard Scaler\"):\n",
    "         \n",
    "        if metodo.lower()==\"standard scaler\":                \n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(df[coluna].to_numpy().reshape(-1, 1))\n",
    "\n",
    "        elif metodo.lower()==\"mix max scaler\":\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(df[coluna].to_numpy().reshape(-1, 1))\n",
    "\n",
    "        else:\n",
    "            print(\"ERRO: Método de normalização não identificado...\")\n",
    "            print(\"Especifique um metódo dentre as opções: Standard Scaler ou MinMax Scaler\")\n",
    "            print(\"O dataframe não foi alterado\")\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def selecao_linhas_(self, df):\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954c090f",
   "metadata": {},
   "source": [
    "## PRÉ-PROCESSAMENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22785644",
   "metadata": {},
   "source": [
    "### 1. Abrir arquivos de linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5826a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Manipulacao = Manipulacao_Arquivos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4285b1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao carregar arquivo: FileNotFoundError(2, 'No such file or directory')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-66d0e8733be8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m df_final = Manipulacao.criar_arquivo_primario(local_origem,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                               \u001b[0marquivo_blihetagem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"BD_Bilhetagem\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                               arquivo_linhas = \"BD_Linhas_Geoespacial\")\n",
      "\u001b[1;32m<ipython-input-3-a662c36703dc>\u001b[0m in \u001b[0;36mcriar_arquivo_primario\u001b[1;34m(self, caminho, arquivo_blihetagem, arquivo_linhas)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mdf_linhas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabrir_arquivo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_origem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BD_Linhas_Geoespacial\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mdf_bilhetagem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LINHA_TRATADA'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_bilhetagem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LINHA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mdf_bilhetagem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LINHA_TRATADA'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_bilhetagem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LINHA_TRATADA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mdf_bilhetagem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LINHA_TRATADA'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_bilhetagem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LINHA_TRATADA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "df_final = Manipulacao.criar_arquivo_primario(local_origem,\n",
    "                                              arquivo_blihetagem = \"BD_Bilhetagem\", \n",
    "                                              arquivo_linhas = \"BD_Linhas_Geoespacial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e375a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nome_Arquivo</th>\n",
       "      <th>Data</th>\n",
       "      <th>Area</th>\n",
       "      <th>Empresa</th>\n",
       "      <th>Linha_Completa</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Total</th>\n",
       "      <th>Linha</th>\n",
       "      <th>Nome_Ponto_Inicial</th>\n",
       "      <th>Sub_Prefeitura</th>\n",
       "      <th>...</th>\n",
       "      <th>Volume_Passageiros_Pagantes</th>\n",
       "      <th>Volume_Pagantes_Dinheiro</th>\n",
       "      <th>Volume_Passageiros_Gratuidade</th>\n",
       "      <th>Volume_BU_Comum</th>\n",
       "      <th>Volume_BU_Vale_Transporte</th>\n",
       "      <th>Volume_Integracao</th>\n",
       "      <th>Volume_BU_Estudante</th>\n",
       "      <th>Volume_Passageiros_BU_VT</th>\n",
       "      <th>Volume_Passageiros_BU_VT_DIN</th>\n",
       "      <th>Zona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8518762</th>\n",
       "      <td>C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V...</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GATUSA</td>\n",
       "      <td>709P10 - TERM GUIDO/PINHEIROS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5991.0</td>\n",
       "      <td>709P10</td>\n",
       "      <td>EST. STO. AMARO , 0</td>\n",
       "      <td>PINHEIROS</td>\n",
       "      <td>...</td>\n",
       "      <td>3348.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>OESTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518763</th>\n",
       "      <td>C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V...</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GATUSA</td>\n",
       "      <td>709P10 - TERM GUIDO/PINHEIROS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5991.0</td>\n",
       "      <td>709P10</td>\n",
       "      <td>TERM. PINHEIROS - PL 6 , 0</td>\n",
       "      <td>PINHEIROS</td>\n",
       "      <td>...</td>\n",
       "      <td>3348.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>OESTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518764</th>\n",
       "      <td>C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V...</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GATUSA</td>\n",
       "      <td>724510 - MORUMBI SHOPPING/EST LUZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9225.0</td>\n",
       "      <td>724510</td>\n",
       "      <td>TERM. STO. AMARO , 0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>5133.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2399.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>CENTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518765</th>\n",
       "      <td>C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V...</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GATUSA</td>\n",
       "      <td>724510 - MORUMBI SHOPPING/EST LUZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9225.0</td>\n",
       "      <td>724510</td>\n",
       "      <td>R. MATO GROSSO , 388</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>5133.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2399.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>CENTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518766</th>\n",
       "      <td>C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V...</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GATUSA</td>\n",
       "      <td>755010 - TERM STO AMARO/M SANTA CECILIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5456.0</td>\n",
       "      <td>755010</td>\n",
       "      <td>TERM. STO. AMARO , 0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>2970.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>CENTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518767</th>\n",
       "      <td>C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V...</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GATUSA</td>\n",
       "      <td>755010 - TERM STO AMARO/M SANTA CECILIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5456.0</td>\n",
       "      <td>755010</td>\n",
       "      <td>TERM. AMARAL GURGEL , 0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>2970.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>CENTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518768</th>\n",
       "      <td>C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V...</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397</td>\n",
       "      <td>9927PR - TERM STO AMARO/TERM BANDEIRA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5282.0</td>\n",
       "      <td>9927PR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>715.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3997.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518769</th>\n",
       "      <td>C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V...</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397</td>\n",
       "      <td>9928PR - TERM BANDEIRA/TERM STO AMARO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4620.0</td>\n",
       "      <td>9928PR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2132.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518770</th>\n",
       "      <td>C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V...</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>292</td>\n",
       "      <td>9945PR - TERMINAL BUTANTA/GATO PRETO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.0</td>\n",
       "      <td>9945PR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518771</th>\n",
       "      <td>C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V...</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>901</td>\n",
       "      <td>SMATEU - TERM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11208.0</td>\n",
       "      <td>SMATEU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3456.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Nome_Arquivo       Data Area  \\\n",
       "8518762  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V... 2024-04-09  NaN   \n",
       "8518763  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V... 2024-04-09  NaN   \n",
       "8518764  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V... 2024-04-09  NaN   \n",
       "8518765  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V... 2024-04-09  NaN   \n",
       "8518766  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V... 2024-04-09  NaN   \n",
       "8518767  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V... 2024-04-09  NaN   \n",
       "8518768  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V... 2024-04-09  NaN   \n",
       "8518769  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V... 2024-04-09  NaN   \n",
       "8518770  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V... 2024-04-09  NaN   \n",
       "8518771  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Projeto V... 2024-04-09  NaN   \n",
       "\n",
       "        Empresa                           Linha_Completa Tipo    Total  \\\n",
       "8518762  GATUSA            709P10 - TERM GUIDO/PINHEIROS  NaN   5991.0   \n",
       "8518763  GATUSA            709P10 - TERM GUIDO/PINHEIROS  NaN   5991.0   \n",
       "8518764  GATUSA        724510 - MORUMBI SHOPPING/EST LUZ  NaN   9225.0   \n",
       "8518765  GATUSA        724510 - MORUMBI SHOPPING/EST LUZ  NaN   9225.0   \n",
       "8518766  GATUSA  755010 - TERM STO AMARO/M SANTA CECILIA  NaN   5456.0   \n",
       "8518767  GATUSA  755010 - TERM STO AMARO/M SANTA CECILIA  NaN   5456.0   \n",
       "8518768     397    9927PR - TERM STO AMARO/TERM BANDEIRA  NaN   5282.0   \n",
       "8518769     397    9928PR - TERM BANDEIRA/TERM STO AMARO  NaN   4620.0   \n",
       "8518770     292     9945PR - TERMINAL BUTANTA/GATO PRETO  NaN    504.0   \n",
       "8518771     901                            SMATEU - TERM  NaN  11208.0   \n",
       "\n",
       "          Linha          Nome_Ponto_Inicial Sub_Prefeitura  ...  \\\n",
       "8518762  709P10         EST. STO. AMARO , 0      PINHEIROS  ...   \n",
       "8518763  709P10  TERM. PINHEIROS - PL 6 , 0      PINHEIROS  ...   \n",
       "8518764  724510        TERM. STO. AMARO , 0             SE  ...   \n",
       "8518765  724510        R. MATO GROSSO , 388             SE  ...   \n",
       "8518766  755010        TERM. STO. AMARO , 0             SE  ...   \n",
       "8518767  755010     TERM. AMARAL GURGEL , 0             SE  ...   \n",
       "8518768  9927PR                         NaN            NaN  ...   \n",
       "8518769  9928PR                         NaN            NaN  ...   \n",
       "8518770  9945PR                         NaN            NaN  ...   \n",
       "8518771  SMATEU                         NaN            NaN  ...   \n",
       "\n",
       "        Volume_Passageiros_Pagantes Volume_Pagantes_Dinheiro  \\\n",
       "8518762                      3348.0                     89.0   \n",
       "8518763                      3348.0                     89.0   \n",
       "8518764                      5133.0                    287.0   \n",
       "8518765                      5133.0                    287.0   \n",
       "8518766                      2970.0                    191.0   \n",
       "8518767                      2970.0                    191.0   \n",
       "8518768                       715.0                     31.0   \n",
       "8518769                      2132.0                     62.0   \n",
       "8518770                       251.0                      0.0   \n",
       "8518771                      5360.0                      0.0   \n",
       "\n",
       "        Volume_Passageiros_Gratuidade  Volume_BU_Comum  \\\n",
       "8518762                         463.0            177.0   \n",
       "8518763                         463.0            177.0   \n",
       "8518764                         790.0            276.0   \n",
       "8518765                         790.0            276.0   \n",
       "8518766                         912.0            140.0   \n",
       "8518767                         912.0            140.0   \n",
       "8518768                         354.0            175.0   \n",
       "8518769                         350.0            200.0   \n",
       "8518770                          76.0              2.0   \n",
       "8518771                        1866.0            263.0   \n",
       "\n",
       "         Volume_BU_Vale_Transporte  Volume_Integracao  Volume_BU_Estudante  \\\n",
       "8518762                        0.0             1827.0                 87.0   \n",
       "8518763                        0.0             1827.0                 87.0   \n",
       "8518764                        0.0             2399.0                340.0   \n",
       "8518765                        0.0             2399.0                340.0   \n",
       "8518766                        0.0             1092.0                151.0   \n",
       "8518767                        0.0             1092.0                151.0   \n",
       "8518768                        0.0             3997.0                 10.0   \n",
       "8518769                        0.0             1827.0                 49.0   \n",
       "8518770                        0.0              115.0                 60.0   \n",
       "8518771                        0.0             3456.0                263.0   \n",
       "\n",
       "         Volume_Passageiros_BU_VT  Volume_Passageiros_BU_VT_DIN    Zona  \n",
       "8518762                     177.0                         266.0   OESTE  \n",
       "8518763                     177.0                         266.0   OESTE  \n",
       "8518764                     276.0                         563.0  CENTRO  \n",
       "8518765                     276.0                         563.0  CENTRO  \n",
       "8518766                     140.0                         331.0  CENTRO  \n",
       "8518767                     140.0                         331.0  CENTRO  \n",
       "8518768                     175.0                         206.0     NaN  \n",
       "8518769                     200.0                         262.0     NaN  \n",
       "8518770                       2.0                           2.0     NaN  \n",
       "8518771                     263.0                         263.0     NaN  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531157c7",
   "metadata": {},
   "source": [
    "### 2. Seleção de Linhas a serem tratadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d438005",
   "metadata": {},
   "source": [
    "##### Critérios definidos para a seleção das linhas a serem tratadas\n",
    "        i. Todos cujo destino não seja Terminais;\n",
    "        ii. Quantos dias distintos eu tenho para cada linha? Enviar para o Roberto DF na segunda 26/02;\n",
    "        iii. Validar existência de outras modalidades de pagamento, além de BU e VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1968bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = Manipulacao.selecao_linhas(df = df_final, \n",
    "                                      apenas_nao_terminais=True,\n",
    "                                      limiar_dias=3650, \n",
    "                                      manter_apenas_modalidades_pagamentos_primarias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17249347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume_Passageiros_BU_VT_DIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ano</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>1423874.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1366570.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1290559.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>1258876.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1193380.469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>613280.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>128954.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>144698.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>410180.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>169111.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>42992.791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Volume_Passageiros_BU_VT_DIN\n",
       "Ano                               \n",
       "2014                   1423874.171\n",
       "2015                   1366570.730\n",
       "2016                   1290559.035\n",
       "2017                   1258876.711\n",
       "2018                   1193380.469\n",
       "2019                    613280.496\n",
       "2020                    128954.686\n",
       "2021                    144698.771\n",
       "2022                    410180.824\n",
       "2023                    169111.831\n",
       "2024                     42992.791"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[['Ano', 'Volume_Passageiros_BU_VT_DIN']].groupby('Ano').sum('Volume_Passageiros_BU_VT_DIN')/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf36d47c",
   "metadata": {},
   "source": [
    "#### 2.1 Definição da \"Linha Mãe\" de cada sub prefeitura?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bdcb365",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linhas_sub_pref, df_linha_mae = Manipulacao.definicao_linhas_maes(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9d5f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linhas_sub_pref.rename(columns={'ds_subpref_tp' : 'Sub_Prefeitura',\n",
    "                                   'LINHA_TRATADA' : 'Linha',\n",
    "                                   'pt_nome_tp'    : 'Nome_Ponto_Inicial',\n",
    "                                   'pt_nome_ts'    : 'Nome_Ponto_Final',\n",
    "                                   'DATA'          : 'Data'}, inplace=True)\n",
    "\n",
    "df_linha_mae.rename(columns={'ds_subpref_tp' : 'Sub_Prefeitura',\n",
    "                                   'LINHA_TRATADA' : 'Linha',\n",
    "                                   'pt_nome_tp'    : 'Nome_Ponto_Inicial',\n",
    "                                   'pt_nome_ts'    : 'Nome_Ponto_Final',\n",
    "                                   'DATA'          : 'Data'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "917b5c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defino as linhas mães de cada subprefeitura\n",
    "df_linha_mae = df_linhas_sub_pref.groupby(by=['Sub_Prefeitura'], \n",
    "                                          as_index=False, \n",
    "                                          sort=False).apply(lambda x: x.loc[x[\"Data\"].idxmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7466310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recupero as demais linhas de cada subprefeitura\n",
    "df_linhas = df_linhas_sub_pref.groupby(by=['Zona', 'Sub_Prefeitura', 'Linha', 'Nome_Ponto_Inicial', 'Nome_Ponto_Final'], \n",
    "                                       as_index=False, \n",
    "                                       sort=False).sum('Data')\n",
    "df_linhas.rename(columns={'Data' : 'Qtde_Dias'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37fd719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação do Boolean de indeitifcação (Mãe, Mantinda, Removida)\n",
    "df_linhas['Mantido'] = np.where(df_linhas['Qtde_Dias']>=3650, 'Mantido', 'Removido')\n",
    "df_linhas['Linha_Mae'] = np.where(df_linhas['Linha'].isin(df_linha_mae['Linha'].values), 'Mãe', 'Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09f27d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mantido</th>\n",
       "      <th>Mantido</th>\n",
       "      <th>Removido</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zona</th>\n",
       "      <th>Sub_Prefeitura</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CENTRO</th>\n",
       "      <th>SE</th>\n",
       "      <td>110.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">LESTE</th>\n",
       "      <th>ARICANDUVA-FORMOSA-CARRAO</th>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERMELINO MATARAZZO</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GUAIANASES</th>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ITAIM PAULISTA</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ITAQUERA</th>\n",
       "      <td>52.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOOCA</th>\n",
       "      <td>60.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PENHA</th>\n",
       "      <td>76.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAO MATEUS</th>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAO MIGUEL</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAPOPEMBA</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VILA PRUDENTE</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">NORTE</th>\n",
       "      <th>CASA VERDE-CACHOEIRINHA</th>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FREGUESIA-BRASILANDIA</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JACANA-TREMEMBE</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERUS</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIRITUBA-JARAGUA</th>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SANTANA-TUCURUVI</th>\n",
       "      <td>44.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VILA MARIA-VILA GUILHERME</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">OESTE</th>\n",
       "      <th>BUTANTA</th>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAPA</th>\n",
       "      <td>67.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PINHEIROS</th>\n",
       "      <td>38.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">SUL</th>\n",
       "      <th>CAMPO LIMPO</th>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAPELA DO SOCORRO</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIDADE ADEMAR</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPIRANGA</th>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JABAQUARA</th>\n",
       "      <td>37.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M BOI MIRIM</th>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARELHEIROS</th>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SANTO AMARO</th>\n",
       "      <td>101.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VILA MARIANA</th>\n",
       "      <td>38.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Mantido                           Mantido  Removido\n",
       "Zona   Sub_Prefeitura                              \n",
       "CENTRO SE                           110.0      50.0\n",
       "LESTE  ARICANDUVA-FORMOSA-CARRAO     12.0       3.0\n",
       "       ERMELINO MATARAZZO             1.0       0.0\n",
       "       GUAIANASES                    17.0       3.0\n",
       "       ITAIM PAULISTA                 6.0       4.0\n",
       "       ITAQUERA                      52.0      13.0\n",
       "       MOOCA                         60.0      13.0\n",
       "       PENHA                         76.0      13.0\n",
       "       SAO MATEUS                    24.0       5.0\n",
       "       SAO MIGUEL                     8.0       1.0\n",
       "       SAPOPEMBA                      3.0       1.0\n",
       "       VILA PRUDENTE                  8.0       5.0\n",
       "NORTE  CASA VERDE-CACHOEIRINHA       14.0       4.0\n",
       "       FREGUESIA-BRASILANDIA          5.0       7.0\n",
       "       JACANA-TREMEMBE                5.0       2.0\n",
       "       PERUS                          1.0       3.0\n",
       "       PIRITUBA-JARAGUA              11.0       8.0\n",
       "       SANTANA-TUCURUVI              44.0      16.0\n",
       "       VILA MARIA-VILA GUILHERME     18.0       6.0\n",
       "OESTE  BUTANTA                       24.0      19.0\n",
       "       LAPA                          67.0      35.0\n",
       "       PINHEIROS                     38.0      13.0\n",
       "SUL    CAMPO LIMPO                   23.0       7.0\n",
       "       CAPELA DO SOCORRO              8.0       7.0\n",
       "       CIDADE ADEMAR                  3.0       4.0\n",
       "       IPIRANGA                      21.0       5.0\n",
       "       JABAQUARA                     37.0       5.0\n",
       "       M BOI MIRIM                   14.0       6.0\n",
       "       PARELHEIROS                   11.0       7.0\n",
       "       SANTO AMARO                  101.0       8.0\n",
       "       VILA MARIANA                  38.0      12.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_linhas[['Zona', 'Sub_Prefeitura', 'Mantido', 'Linha']].groupby(['Zona', 'Sub_Prefeitura', 'Mantido'], as_index=False).count().pivot(index=['Zona', 'Sub_Prefeitura'],\n",
    "                                                                                                                       columns='Mantido',\n",
    "                                                                                                                       values='Linha').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53d2a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linhas.to_csv(\"df_linhas.csv\", sep=\";\", encoding=\"latin-1\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1974ec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linha_mae.to_csv(\"df_linha_mae.csv\", sep=\";\", encoding=\"latin-1\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f8823a",
   "metadata": {},
   "source": [
    "### 3. Tratamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43ce14a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pre_Process = PreProcessamento()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72be92cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtro Apenas as linhas que serão utilizadas\n",
    "df_final = df_final[df_final['Linha'].isin(np.unique(df_linhas[df_linhas['Mantido']=='Mantido']['Linha']))]\n",
    "df_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f94a86b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume_Passageiros_BU_VT_DIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ano</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>1311887.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1235573.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1162858.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>1131464.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1067902.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>546525.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>115872.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>128848.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>363930.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>149459.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>37710.173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Volume_Passageiros_BU_VT_DIN\n",
       "Ano                               \n",
       "2014                   1311887.025\n",
       "2015                   1235573.257\n",
       "2016                   1162858.735\n",
       "2017                   1131464.722\n",
       "2018                   1067902.320\n",
       "2019                    546525.575\n",
       "2020                    115872.652\n",
       "2021                    128848.486\n",
       "2022                    363930.283\n",
       "2023                    149459.969\n",
       "2024                     37710.173"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[['Ano', 'Volume_Passageiros_BU_VT_DIN']].groupby('Ano').sum('Volume_Passageiros_BU_VT_DIN')/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cc99b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = Pre_Process.tratar_dados_ausentes_(df_final, \n",
    "                                              coluna=\"Volume_Passageiros_BU_VT_DIN\", \n",
    "                                              grupo=\"Linha\",\n",
    "                                              metodo=\"média\")\n",
    "df_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74fdc97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume_Passageiros_BU_VT_DIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ano</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>131196.089108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>123563.428604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>116288.796248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>113171.476710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>106888.815672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>54806.645221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>11825.315616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>13116.170968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>36531.140888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>15994.209911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>7495.416825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Volume_Passageiros_BU_VT_DIN\n",
       "Ano                               \n",
       "2014                 131196.089108\n",
       "2015                 123563.428604\n",
       "2016                 116288.796248\n",
       "2017                 113171.476710\n",
       "2018                 106888.815672\n",
       "2019                  54806.645221\n",
       "2020                  11825.315616\n",
       "2021                  13116.170968\n",
       "2022                  36531.140888\n",
       "2023                  15994.209911\n",
       "2024                   7495.416825"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[['Ano', 'Volume_Passageiros_BU_VT_DIN']].groupby('Ano').sum('Volume_Passageiros_BU_VT_DIN')/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8152040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = Pre_Process.corrigir_outliers(df_final,\n",
    "                                         coluna=\"Volume_Passageiros_BU_VT_DIN\",\n",
    "                                         metodo=\"interquartil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e70170b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume_Passageiros_BU_VT_DIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ano</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>131182.807108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>123560.463804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>116288.288448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>113171.476710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>106888.644172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>54806.645221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>11825.315616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>13116.170968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>36530.443588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>15993.997311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>7495.416825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Volume_Passageiros_BU_VT_DIN\n",
       "Ano                               \n",
       "2014                 131182.807108\n",
       "2015                 123560.463804\n",
       "2016                 116288.288448\n",
       "2017                 113171.476710\n",
       "2018                 106888.644172\n",
       "2019                  54806.645221\n",
       "2020                  11825.315616\n",
       "2021                  13116.170968\n",
       "2022                  36530.443588\n",
       "2023                  15993.997311\n",
       "2024                   7495.416825"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[['Ano', 'Volume_Passageiros_BU_VT_DIN']].groupby('Ano').sum('Volume_Passageiros_BU_VT_DIN')/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed9c6c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataframe não foi alterado\n"
     ]
    }
   ],
   "source": [
    "df_final = Pre_Process.transformacao_dados_(df_final,\n",
    "                                            coluna=\"Volume_Passageiros_BU_VT_DIN\",\n",
    "                                            grupo=\"LINHA_TRATADA\", \n",
    "                                            metodo=\"nenhum\")\n",
    "df_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71f72f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ano</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Zona</th>\n",
       "      <th>Sub_Prefeitura</th>\n",
       "      <th>Linha_Completa</th>\n",
       "      <th>Linha</th>\n",
       "      <th>Empresa</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Nome_Ponto_Inicial</th>\n",
       "      <th>Volume_Passageiros_BU_VT_DIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>SE</td>\n",
       "      <td>115610 - VILA SABRINA/PC DO CORREIO</td>\n",
       "      <td>115610</td>\n",
       "      <td>SAMBAIBA</td>\n",
       "      <td>CONCESSAO</td>\n",
       "      <td>PÇA. CARLOS KOSERITZ , 0</td>\n",
       "      <td>136186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>SE</td>\n",
       "      <td>115610 - VILA SABRINA/PC DO CORREIO</td>\n",
       "      <td>115610</td>\n",
       "      <td>SAMBAIBA</td>\n",
       "      <td>CONCESSAO</td>\n",
       "      <td>PÇA. DO CORREIO , 0</td>\n",
       "      <td>136186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>SE</td>\n",
       "      <td>117710 - TERM.A.E.CARVALHO-EST.LUZ</td>\n",
       "      <td>117710</td>\n",
       "      <td>VIP II</td>\n",
       "      <td>CONCESSAO</td>\n",
       "      <td>R. MAUÁ , 790</td>\n",
       "      <td>83168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>SE</td>\n",
       "      <td>117810 - SAO MIGUEL-PCA DO CORREIO</td>\n",
       "      <td>117810</td>\n",
       "      <td>VIP II</td>\n",
       "      <td>CONCESSAO</td>\n",
       "      <td>PÇA. ANTÔNIO ASSIS PEREIRA , 1040</td>\n",
       "      <td>198328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>SE</td>\n",
       "      <td>117810 - SAO MIGUEL-PCA DO CORREIO</td>\n",
       "      <td>117810</td>\n",
       "      <td>VIP II</td>\n",
       "      <td>CONCESSAO</td>\n",
       "      <td>R. RISKALLAH JORGE , 80</td>\n",
       "      <td>198328.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ano  Mes    Zona Sub_Prefeitura                       Linha_Completa  \\\n",
       "0  2014    1  CENTRO             SE  115610 - VILA SABRINA/PC DO CORREIO   \n",
       "1  2014    1  CENTRO             SE  115610 - VILA SABRINA/PC DO CORREIO   \n",
       "2  2014    1  CENTRO             SE   117710 - TERM.A.E.CARVALHO-EST.LUZ   \n",
       "3  2014    1  CENTRO             SE   117810 - SAO MIGUEL-PCA DO CORREIO   \n",
       "4  2014    1  CENTRO             SE   117810 - SAO MIGUEL-PCA DO CORREIO   \n",
       "\n",
       "    Linha   Empresa       Tipo                 Nome_Ponto_Inicial  \\\n",
       "0  115610  SAMBAIBA  CONCESSAO           PÇA. CARLOS KOSERITZ , 0   \n",
       "1  115610  SAMBAIBA  CONCESSAO                PÇA. DO CORREIO , 0   \n",
       "2  117710    VIP II  CONCESSAO                      R. MAUÁ , 790   \n",
       "3  117810    VIP II  CONCESSAO  PÇA. ANTÔNIO ASSIS PEREIRA , 1040   \n",
       "4  117810    VIP II  CONCESSAO            R. RISKALLAH JORGE , 80   \n",
       "\n",
       "   Volume_Passageiros_BU_VT_DIN  \n",
       "0                      136186.0  \n",
       "1                      136186.0  \n",
       "2                       83168.0  \n",
       "3                      198328.0  \n",
       "4                      198328.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_agrupado_anomes = df_final[['Zona', 'Sub_Prefeitura', 'Linha_Completa', 'Linha', 'Empresa',  'Tipo',  'Nome_Ponto_Inicial', 'Volume_Passageiros_BU_VT_DIN', 'Ano', 'Mes']].groupby(['Ano', 'Mes', 'Zona', 'Sub_Prefeitura', 'Linha_Completa', 'Linha', 'Empresa',  'Tipo',  'Nome_Ponto_Inicial'], as_index=False).sum('Volume_Passageiros_BU_VT_DIN')\n",
    "df_final_agrupado_anomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d967e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_agrupado_anomes['Linha_Mae'] = np.where(df_final_agrupado_anomes['Linha'].isin(df_linha_mae['Linha']), \"Sim\", \"Não\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0a928dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Manipulacao.salvar_arquivo(local_destino, df_final_agrupado_anomes, 'df_final_agrupado_ano_mes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "054384aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Manipulacao.salvar_arquivo(local_destino, df_final, 'df_final_tratado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4746b5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3438312 entries, 0 to 3438311\n",
      "Data columns (total 26 columns):\n",
      " #   Column                         Dtype         \n",
      "---  ------                         -----         \n",
      " 0   Nome_Arquivo                   object        \n",
      " 1   Data                           datetime64[ns]\n",
      " 2   Area                           object        \n",
      " 3   Empresa                        object        \n",
      " 4   Linha_Completa                 object        \n",
      " 5   Tipo                           object        \n",
      " 6   Total                          float64       \n",
      " 7   Linha                          object        \n",
      " 8   Nome_Ponto_Inicial             object        \n",
      " 9   Sub_Prefeitura                 object        \n",
      " 10  Lat_Long_Ponto_Inicial         object        \n",
      " 11  Nome_Ponto_Final               object        \n",
      " 12  Lat_Long_Ponto_Final           object        \n",
      " 13  Ano                            int32         \n",
      " 14  Mes                            int32         \n",
      " 15  Dia                            int32         \n",
      " 16  Volume_Passageiros_Pagantes    float64       \n",
      " 17  Volume_Pagantes_Dinheiro       float64       \n",
      " 18  Volume_Passageiros_Gratuidade  float64       \n",
      " 19  Volume_BU_Comum                float64       \n",
      " 20  Volume_BU_Vale_Transporte      float64       \n",
      " 21  Volume_Integracao              float64       \n",
      " 22  Volume_BU_Estudante            float64       \n",
      " 23  Volume_Passageiros_BU_VT       float64       \n",
      " 24  Volume_Passageiros_BU_VT_DIN   float64       \n",
      " 25  Zona                           object        \n",
      "dtypes: datetime64[ns](1), float64(10), int32(3), object(12)\n",
      "memory usage: 642.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaed28b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
