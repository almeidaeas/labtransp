{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc803859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unicodecsv as csv\n",
    "\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import zipfile\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559e4a7c",
   "metadata": {},
   "source": [
    "# <center> Download dos dados de Bilhetagem da SPTrans </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9c41b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio = \"C:\\\\Users\\\\f112596\\\\Desktop\\\\Projetos\\\\DO\\\\Lab Transp\" #\"C:/Users/usuario/Pasta Raiz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2710d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DEFINIÇÃO DAS ROTINAS A SEREM EXECUTADAS:\n",
    "\"\"\"\n",
    "Download_BD_Atualizacao = 0\n",
    "Download_BD_Historico = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7677fefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classe_Geral(object):\n",
    "    #Crawler\n",
    "    url_principal = \"https://capital.sp.gov.br/web/mobilidade/w/passageiros-transportados-2025\"\n",
    "    url_2014 = \"https://www.prefeitura.sp.gov.br/cidade/secretarias/mobilidade/institucional/sptrans/acesso_a_informacao/index.php?p=152417\"\n",
    "    url_2013 = \"https://www.prefeitura.sp.gov.br/cidade/secretarias/mobilidade/institucional/sptrans/acesso_a_informacao/index.php?p=164379\"\n",
    "\n",
    "    def carregar_Anos_Consulta(self):\n",
    "        \"\"\"\n",
    "        Este método carrega os anos para os quais\n",
    "        existem dados disponíves na url_principal\n",
    "        \"\"\"\n",
    "        r1 = requests.get(self.url_principal)\n",
    "        coverpage = r1.content\n",
    "        soup = BeautifulSoup(coverpage, 'html5lib')\n",
    "\n",
    "\n",
    "        result_set = soup.find_all(\"div\", {\"class\": \"psp-agencies-content__content\"})\n",
    "        anos_disponiveis = result_set[0].find_all(\"a\")\n",
    "\n",
    "        ano = 0\n",
    "        lista_anos = []        \n",
    "        lista_anos.append(2025) #url Principal\n",
    "        \n",
    "        for elem in anos_disponiveis:\n",
    "            try:\n",
    "                ano = int(elem.get_text())\n",
    "                if ano >= 2000:\n",
    "                    lista_anos.append(ano)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        return lista_anos, result_set\n",
    "    \n",
    "    def criar_Relacao_Datas(self, lista_anos):\n",
    "        \"\"\"\n",
    "        Para garantir que todos os arquivos sejam baixados\n",
    "        e validar a consistência do banco de dados,\n",
    "        crio uma relação de datas, que deverão ser checadas:\n",
    "                                                            i) no banco e \n",
    "                                                            ii) na página para download    \n",
    "        \"\"\"\n",
    "        data_base = datetime.date.today()\n",
    "        data_inicial = datetime.date(np.min(lista_anos), 1, 1)\n",
    "\n",
    "        lista_datas = [data_base - timedelta(days=x) for x in range((data_base-data_inicial).days)]\n",
    "        \n",
    "        \n",
    "        #Montagem do dicionário de log\n",
    "        dict_log_datas = {}\n",
    "        for data in lista_datas:\n",
    "            dict_log_datas[data] = \"Não Baixado\"\n",
    "\n",
    "        return dict_log_datas\n",
    "    \n",
    "    def criar_Relacao_Datas_Atualizacao(self, dict_log_datas):\n",
    "        \"\"\"\n",
    "        Para garantir que todos os arquivos sejam baixados\n",
    "        e validar a consistência do banco de dados,\n",
    "        crio uma relação de datas, que deverão ser checadas:\n",
    "                                                            i) no banco e \n",
    "                                                            ii) na página para download    \n",
    "        \"\"\"\n",
    "        data_base = datetime.date.today()\n",
    "        \n",
    "        chave_ultimo_download = [k for k, v in dict_log_datas.items() if v[1] == 'Baixado'][0]\n",
    "        data_ultimo_download = datetime.datetime.strptime(dict_log_datas[chave_ultimo_download][0], '%Y-%m-%d')\n",
    "        data_inicial = (data_ultimo_download + datetime.timedelta(days=1)).date()\n",
    "        \n",
    "        lista_datas = [data_base - timedelta(days=x) for x in range((data_base-data_inicial).days)]\n",
    "        \n",
    "        dict_log_datas = {}\n",
    "        for data in lista_datas:\n",
    "            dict_log_datas[data] = \"Não Baixado\"\n",
    "\n",
    "        return dict_log_datas\n",
    "    \n",
    "    \n",
    "    def carregar_Href_Ano(self, ano, result_set):\n",
    "        \"\"\"\n",
    "        Carregar o href do ano selecionado\n",
    "        \"\"\" \n",
    "        if ano == '2014':\n",
    "            return self.url_2014\n",
    "        \n",
    "        elif ano == \"2013\":\n",
    "            return self.url_2013\n",
    "\n",
    "        elif ano == \"2025\":\n",
    "            return self.url_principal        \n",
    "        \n",
    "        else:\n",
    "            for elem in result_set[0].find_all(\"a\"):\n",
    "                if elem.get_text().strip() == ano:\n",
    "                    if elem['href'][0:6] != \"https:\": \n",
    "                        url = \"https://capital.sp.gov.br\" + elem['href']\n",
    "                    else:\n",
    "                        url = elem['href']\n",
    "                    \n",
    "                    return url \n",
    "            \n",
    "           \n",
    "    def carregar_Href_datas(self, url):\n",
    "        \"\"\"\n",
    "        Com base em uma url do ano seleciona\n",
    "        realizada as buscas das urls dos arquivos\n",
    "        \"\"\"\n",
    "        r1 = requests.get(url)\n",
    "        coverpage = r1.content\n",
    "        soup = BeautifulSoup(coverpage, 'html5lib')\n",
    "\n",
    "        result_set = soup.find_all(\"td\")\n",
    "\n",
    "        lista_url_arquivos = []\n",
    "        for elem in result_set:\n",
    "            if elem.get_text() not in ['Dom', 'Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'Sáb', 'Total', '\\xa0']:\n",
    "                try:\n",
    "                    if \"Consolidado\" not in elem.find_all(\"a\")[0]['href']:\n",
    "                        lista_url_arquivos.append(elem.find_all(\"a\")[0]['href'])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        return lista_url_arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b1eaa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gerenciador_Download(object):    \n",
    "    \n",
    "    def criar_Chave_Meses(self):\n",
    "        \"\"\"\n",
    "        As urls da SPTRANS vêm com o padrão de mês MMM e eu preciso de um int\n",
    "        Por isso uso esse dict\n",
    "        \"\"\"\n",
    "        dict_chave_meses = {\"JAN\" : 1,\n",
    "                            \"FEV\" : 2,\n",
    "                            \"MAR\" : 3,\n",
    "                            \"ABR\" : 4,\n",
    "                            \"MAI\" : 5,\n",
    "                            \"JUN\" : 6,\n",
    "                            \"JUL\" : 7,\n",
    "                            \"AGO\" : 8,\n",
    "                            \"SET\" : 9,\n",
    "                            \"OUT\" : 10,\n",
    "                            \"NOV\" : 11,\n",
    "                            \"DEZ\" : 12}  \n",
    "        return dict_chave_meses\n",
    "    \n",
    "    \n",
    "    \n",
    "    def mapeamento_Arquivos(self, lista_arquivos, ano):\n",
    "        \"\"\"\n",
    "        Defino a relação de arquivos disponíveis, criando um dicionário, \n",
    "        cuja chave é o nome/data do arquivo        \n",
    "        \"\"\"\n",
    "\n",
    "        dict_chave_meses = self.criar_Chave_Meses()\n",
    "\n",
    "        dict_arquivos_disponiveis = {}    \n",
    "        \n",
    "        for arquivo in lista_arquivos:\n",
    "            inicio = arquivo.find(\"upload/\") + len(\"upload/\")\n",
    "            final = arquivo.find(\".xls\")\n",
    "\n",
    "            #Formato: DDMMMAAAA ou \"ddmmaa(1)\"\n",
    "            if (len(arquivo[inicio : final]) == 9)  or (len(arquivo[inicio : final]) == 12):\n",
    "                try:\n",
    "                    data_ref_arquivo = datetime.date(int(arquivo[inicio : final][5:9]),\n",
    "                                                     dict_chave_meses[arquivo[inicio : final][2:5]],\n",
    "                                                     int(arquivo[inicio : final][0:2]))    \n",
    "                except:\n",
    "                    novo_final = arquivo[inicio : final].find(\"(\")\n",
    "                    data_ref_arquivo = datetime.date(int(str(20) + arquivo[inicio : inicio + novo_final][4:6]),\n",
    "                                                     int(arquivo[inicio : inicio + novo_final][2:4]),\n",
    "                                                     int(arquivo[inicio : inicio + novo_final][0:2]))                    \n",
    "            \n",
    "            #Formato: DDMMAAAA\n",
    "            elif (len(arquivo[inicio : final]) == 11):\n",
    "                data_ref_arquivo = datetime.date(int(arquivo[inicio : final][4:8]),\n",
    "                                     int(arquivo[inicio : final][2:4]),\n",
    "                                     int(arquivo[inicio : final][0:2]))\n",
    "            \n",
    "            #Formato: ddmmaaaa\n",
    "            elif len(arquivo[inicio : final]) == 8:\n",
    "                data_ref_arquivo = datetime.date(int(arquivo[inicio : final][4:9]),\n",
    "                                             int(arquivo[inicio : final][2:4]),                                 \n",
    "                                             int(arquivo[inicio : final][0:2]))\n",
    "\n",
    "\n",
    "            #Formato: \"ddmmaaaa_Dados para Transparência\"\n",
    "            elif (len(arquivo[inicio : final]) == 33) or (len(arquivo[inicio : final]) == 36):\n",
    "                novo_final = arquivo[inicio : final].find(\"_Dados para Transparência\")\n",
    "                data_ref_arquivo = datetime.date(int(arquivo[inicio : inicio + novo_final][4:9]),\n",
    "                                         int(arquivo[inicio : inicio + novo_final][2:4]),                                 \n",
    "                                         int(arquivo[inicio : inicio + novo_final][0:2]))\n",
    "\n",
    "            #Formato: DD-MMM ou \"ddmmaa\"\n",
    "            elif len(arquivo[inicio : final]) == 6:\n",
    "                try:\n",
    "                    data_ref_arquivo = datetime.date(ano,\n",
    "                                                 dict_chave_meses[arquivo[inicio : final][3:6]],\n",
    "                                                 int(arquivo[inicio : final][0:2]))\n",
    "                \n",
    "                except:                \n",
    "                    data_ref_arquivo = datetime.date(int(str(20) + arquivo[inicio : final][4:6]),\n",
    "                                                 int(arquivo[inicio : final][2:4]),\n",
    "                                                 int(arquivo[inicio : final][0:2]))             \n",
    "                \n",
    "                \n",
    "            #Formato: \"Passag-AAAAMMDD\"\n",
    "            elif len(arquivo[inicio : final]) == 15 or len(arquivo[inicio : final]) == 18:\n",
    "                novo_inicio = inicio + len(\"Passag-\")    \n",
    "                data_ref_arquivo = datetime.date(int(arquivo[novo_inicio : final][0:4]),\n",
    "                                                 int(arquivo[novo_inicio : final][4:6]),\n",
    "                                                 int(arquivo[novo_inicio : final][6:8]))      \n",
    "\n",
    "                \n",
    "                \n",
    "            #Formato: \"ddmmaaaa_Dados para Transparência\"\n",
    "                # no subditerório 'upload/transportes/SPTrans/acesso_a_informacao/2017/janeiro/passageiros/'\n",
    "            elif (len(arquivo[inicio : final]) >= 77 and len(arquivo[inicio : final]) <= 82) or ( len(arquivo[inicio : final]) in [57, 58, 60, 62]):\n",
    "                try:\n",
    "                    novo_inicio = arquivo.find(\"passageiros/\") + len(\"passageiros/\")\n",
    "                    novo_inicio_2 = novo_inicio + len(\"Passag-\")    \n",
    "                    data_ref_arquivo = datetime.date(int(arquivo[novo_inicio_2 : final][0:4]),\n",
    "                                                     int(arquivo[novo_inicio_2 : final][4:6]),\n",
    "                                                     int(arquivo[novo_inicio_2 : final][6:8]))  \n",
    "                except:\n",
    "                    try:\n",
    "                        novo_inicio = arquivo.find(\"Pass_Transp_\") + len(\"Pass_Transp_\")\n",
    "                        data_ref_arquivo = datetime.date(int(ano),\n",
    "                                                         int(dict_chave_meses[arquivo[novo_inicio : final][0:3].upper()]),\n",
    "                                                         int(arquivo[novo_inicio : final][3:6]))  \n",
    "                    except:\n",
    "                        #Nesses casos, podem haver erro na nomemclatura do arquivo (Ex. 201300901)\n",
    "                        novo_inicio = arquivo.find(\"Passag-\") + len(\"Passag-\")\n",
    "                        data_ref_arquivo = datetime.date(int(arquivo[novo_inicio : final][0:4]),\n",
    "                                                         int(arquivo[novo_inicio : final][5:7]),\n",
    "                                                         int(arquivo[novo_inicio : final][7:9]))\n",
    "\n",
    "            \n",
    "            #Formato: \"Passag-AAAAMMDD\"\n",
    "            elif (len(arquivo[inicio : final]) == 59) or (len(arquivo[inicio : final]) == 61) or  (len(arquivo[inicio : final]) == 64):\n",
    "                novo_inicio = (arquivo.find(\"Passag-\") + len(\"Passag-\"))\n",
    "                data_ref_arquivo = datetime.date(int(arquivo[novo_inicio : final][0:4]),\n",
    "                                                     int(arquivo[novo_inicio : final][4:6]),\n",
    "                                                     int(arquivo[novo_inicio : final][6:8]))\n",
    "                \n",
    "            \n",
    "            #Formato: \"Passag-Transportados-AAAAMMDD\"\n",
    "            elif (len(arquivo[inicio : final]) == 72) or (len(arquivo[inicio : final]) == 73):\n",
    "                novo_inicio = (arquivo.find(\"Passag-Transportados\") + len(\"Passag-Transportados\"))\n",
    "                data_ref_arquivo = datetime.date(int(arquivo[novo_inicio : final][1:5]),\n",
    "                                                     int(arquivo[novo_inicio : final][5:7]),\n",
    "                                                     int(arquivo[novo_inicio : final][7:9]))  \n",
    "                                    \n",
    "            \n",
    "            #Formato: Novo diretório para download \"arquivo[0:10] == '/documents'\"\n",
    "            elif arquivo[0:10] == '/documents':\n",
    "                novo_arquivo = arquivo[len('/documents/d/mobilidade/') : len(arquivo)-4]\n",
    "                data_ref_arquivo = datetime.date(int(novo_arquivo[5:9]),\n",
    "                                                 dict_chave_meses[novo_arquivo[2:5].upper()],\n",
    "                                                 int(novo_arquivo[0:2]))\n",
    "            \n",
    "            \n",
    "            else:\n",
    "                data_ref_arquivo = None\n",
    "\n",
    "\n",
    "            if data_ref_arquivo != None:\n",
    "                if arquivo[0:10] == '/documents':\n",
    "                    arquivo = 'https://capital.sp.gov.br' + arquivo\n",
    "                    \n",
    "                dict_arquivos_disponiveis[data_ref_arquivo] = [arquivo, \"Não Baixado\"]\n",
    "            \n",
    "            \n",
    "        return dict_arquivos_disponiveis\n",
    "\n",
    "    #Limpo o diretorio temporário de arquivos do tipo .ZIP e .TXT\n",
    "    def limpar_Diretorio(self):\n",
    "        arquivos_temp = glob.glob(diretorio + '/temp_downloads/*')\n",
    "        for temp in arquivos_temp:\n",
    "            os.remove(temp)\n",
    "\n",
    "    \n",
    "    def download_Arquivos(self, dict_log_datas, dict_arquivos_disponiveis, ano):\n",
    "        \"\"\"\n",
    "        Método responsável pelo download dos arquivos.\n",
    "        Data uma lista de datas e de um dincionário de arquivos disponíveis no site,\n",
    "        ele irá fazer o download e escrever um log de download\n",
    "        \"\"\"                \n",
    "        \n",
    "        for data, log in dict_log_datas.items():\n",
    "            if data.year == ano:\n",
    "                try:\n",
    "                    #Tento fazer o download no diretório temporário\n",
    "                    wget.download(dict_arquivos_disponiveis[data][0],\n",
    "                                                                    out = diretorio + \"/temp_downloads/Bilhetagem_\" \n",
    "                                                                                                            + str(data.year) + \"_\" \n",
    "                                                                                                            + str(data.month) + \"_\"\n",
    "                                                                                                            + str(data.day) \n",
    "                                                                                                            + \".xls\")\n",
    "                    \n",
    "                    time.sleep(2)\n",
    "                    \n",
    "                    #Atualizo o log\n",
    "                    dict_log_datas[data] = \"Baixado\"\n",
    "                    dict_arquivos_disponiveis[data][1] = \"Baixado\"\n",
    "                except BaseException as e:\n",
    "                    try:\n",
    "                        dict_log_datas[data] = str(e)\n",
    "                        dict_arquivos_disponiveis[data][1] = str(e)\n",
    "                    except:\n",
    "                        dict_log_datas[data] = 'Sem referencia'\n",
    "                        #dict_arquivos_disponiveis[data][1] = 'Sem referencia'\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        return dict_log_datas\n",
    "    \n",
    "    def salvar_log(self, dict_log_datas):\n",
    "        dic_log = {}\n",
    "        i = 0\n",
    "        \n",
    "        for data, log in dict_log_datas.items():\n",
    "            dic_log[i] = [str(data), log]\n",
    "            i = i +1        \n",
    "        \n",
    "        try:\n",
    "            with open(diretorio + \"\\log_download_bilhetagem.json\", \"w\") as log_file:\n",
    "                json.dump(dic_log , log_file)\n",
    "            print(\"Log de download salvo no diretório: \", diretorio + \"/log_download_bilhetagem.json\" )\n",
    "        except BaseException as e:\n",
    "            print(\"ERRO! Log de download não pode ser salvo! \" + str(e))\n",
    "\n",
    "            \n",
    "            \n",
    "    def atualizar_log(self, dict_log_datas, dict_log_datas_novo):\n",
    "        dic_log = {}\n",
    "        i = 0\n",
    "        \n",
    "        #Adicono os ados do logo novo    \n",
    "        for data, log in dict_log_datas_novo.items():\n",
    "            dic_log[i] = [str(data), log]\n",
    "            i = i +1     \n",
    "\n",
    "        #Adiciono os dados do log antigo\n",
    "        for chave, log in dict_log_datas.items():\n",
    "            dic_log[i] = [log[0], log[1]]\n",
    "            i = i +1\n",
    "\n",
    "        try:\n",
    "            with open(diretorio + \"\\log_download_bilhetagem.json\", \"w\") as log_file:\n",
    "                json.dump(dic_log , log_file)\n",
    "            print(\"Log de download salvo no diretório: \", diretorio + \"/log_download_bilhetagem.json\" )\n",
    "        except BaseException as e:\n",
    "            print(\"ERRO! Log de download não pode ser salvo! \" + str(e))            \n",
    "            \n",
    "                        \n",
    "    def ler_log(self):\n",
    "        with open(diretorio + \"\\log_download_bilhetagem.json\") as dict_log_datas:\n",
    "            dict_log_datas = json.load(dict_log_datas)\n",
    "        return dict_log_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8bc554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class consolidador_Arquivos(object):    \n",
    "    def listar_Arquivos(self):        \n",
    "        arquivos_temp = glob.glob(diretorio + '/temp_downloads/*')        \n",
    "        return arquivos_temp\n",
    "    \n",
    "    \"\"\"\n",
    "    Esse método carrega o DF já disponível com os dados\n",
    "    Se não houver um arquivo disponível, ele criará um vazio    \n",
    "    \"\"\"\n",
    "    def criar_Df_Bilhetagem(self):\n",
    "        #Se o BD existir\n",
    "        if os.path.isfile(diretorio + \"/BD_Bilhetagem.csv\") == True:\n",
    "            df = pd.read_csv(diretorio + \"/BD_Bilhetagem.csv\", encoding='latin-1')\n",
    "            \n",
    "        else:\n",
    "            df = pd.DataFrame(columns=self.ordem_Colunas())\n",
    "            print(\"Um banco de dados não pode ser encotrando em \" + diretorio)\n",
    "            print(\"Um novo banco de dados está sendo criado para a extração corrente...\")\n",
    "        return df\n",
    "    \n",
    "    def carregar_Arquivo(self, arquivo):\n",
    "        #dic_colunas_depara = self.carregar_DePara_Colunas()\n",
    "        \n",
    "        try:\n",
    "            i = 0 \n",
    "            plan = pd.read_excel(arquivo, skiprows = range(0, i))\n",
    "            while plan.columns[0].upper()[0:9] == 'RELATÓRIO' or plan.columns[0] == 'Unnamed: 0':\n",
    "                i = i + 1\n",
    "                plan = pd.read_excel(arquivo, skiprows = range(0, i))\n",
    "\n",
    "            \n",
    "            #Defino os novos nomes da coluna, baseado no De-Para\n",
    "            colunas = (plan.columns.str.upper().str.strip()).to_series().map(self.carregar_DePara_Colunas())\n",
    "            plan = plan.set_axis(colunas, axis=1)\n",
    "            \n",
    "            #As colunas que não estão no De-Para são excluídas\n",
    "            plan.columns = plan.columns.fillna('excluir')\n",
    "            plan.drop('excluir', axis = 1, inplace = True)\n",
    "            \n",
    "            #Para garatnir consistência, i) excluo o coluna de DATA e...           \n",
    "            plan = plan.drop(['DATA', 'Data'], axis=1, errors='ignore')\n",
    "            \n",
    "            #ii) Crio uma nova coluna de Data (como nome do arquivo)\n",
    "            data_ref = arquivo[arquivo.find('Bilhetagem_')+len('Bilhetagem_'):arquivo.find('.xls')]\n",
    "            plan['DATA'] = datetime.datetime.strptime(data_ref, '%Y_%m_%d')\n",
    "            \n",
    "            #Crio uma nova coluna como Nome do Arquivo            \n",
    "            plan['NOME_ARQUIVO'] = arquivo\n",
    "                                    \n",
    "            plan = plan.reindex(self.ordem_Colunas(), axis=1)\n",
    "                        \n",
    "            return True, plan\n",
    "        \n",
    "        except BaseException as e:   \n",
    "            print(\"ERRO! Não foi possível carregar arquivo \" + str(arquivo))\n",
    "            print(str(e))\n",
    "            return False, None\n",
    "        \n",
    "        \n",
    "    def carregar_DePara_Colunas(self):\n",
    "        try:\n",
    "            with open(diretorio + '/De_Para_Colunas.json') as de_para:\n",
    "                dic_colunas_depara  = json.load(de_para)\n",
    "                return dic_colunas_depara\n",
    "        except BaseException as e:\n",
    "            print(\"ERRO! Não foi possível carregar o De-Para de Colunas! \" + str(e))     \n",
    "            \n",
    "            \n",
    "    def ordem_Colunas(self):        \n",
    "        ordem_colunas = ['NOME_ARQUIVO', 'DATA', 'AREA', 'EMPRESA', 'LINHA', 'TIPO', 'PASSAGEIROS_GRATUIDADE', \n",
    "            'PASSAGEIROS_GRATUIDADE_ESTUDANTE', 'PASSAGEIROS_PAGANTES', 'PASSAGEIROS_PAGANTES_BU_COMUM', \n",
    "            'PASSAGEIROS_PAGANTES_BU_COMUM_MENSAL', 'PASSAGEIROS_PAGANTES_BU_ESTUDANTES', \n",
    "            'PASSAGEIROS_PAGANTES_BU_ESTUDANTES_MENSAL', 'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP', \n",
    "            'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP_MENSAL', 'PASSAGEIROS_PAGANTES_DINHEIRO', 'PASSAGEIROS_PAGANTES_ESTUDANTES', \n",
    "            'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_METRO_CPTM', 'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_ONIBUS', \n",
    "            'TOTAL']\n",
    "        \n",
    "        return ordem_colunas\n",
    "        \n",
    "                \n",
    "    '''\n",
    "    PROCESSO PARA RECARREGAMENTO DOS DADOS\n",
    "    '''    \n",
    "    def definir_Colunas(self, Lista_Colunas):\n",
    "        Cols_Remover = ['Unnamed: 0', 'Unnamed: 1','Unnamed: 2','Unnamed: 3','Unnamed: 4','Unnamed: 5','Unnamed: 6','Unnamed: 7','Unnamed: 8',\n",
    "                        'Unnamed: 9','Unnamed: 10','Unnamed: 11','Unnamed: 12','Unnamed: 13','Unnamed: 14','Unnamed: 15','Unnamed: 16',\n",
    "                        'Unnamed: 17','Unnamed: 18','Unnamed: 19','Unnamed: 20','Unnamed: 21','Unnamed: 22','Unnamed: 23','Unnamed: 24',\n",
    "                        'Unnamed: 25','Unnamed: 26','Unnamed: 27', 'DATA','Data']\n",
    "        \n",
    "        Cols_Manter = []\n",
    "        for col in list(set(Lista_Colunas)):\n",
    "            if col not in Cols_Remover:\n",
    "                Cols_Manter.append(col)\n",
    "        return Cols_Manter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b01a533",
   "metadata": {},
   "source": [
    "## Instanciação das Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e392ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "Crawler = None\n",
    "Gerenciador = None\n",
    "Consolidador = None\n",
    "\n",
    "Crawler = Classe_Geral()\n",
    "Gerenciador = gerenciador_Download()\n",
    "Consolidador = consolidador_Arquivos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc9e5a9",
   "metadata": {},
   "source": [
    "## Execução das Rotinas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19774ac5",
   "metadata": {},
   "source": [
    "## Atualização do BD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d85de30",
   "metadata": {},
   "source": [
    "#### i. Download dos arquivos não disponíveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf0929",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Para o caso de fazer download \n",
    "apenas das datas não presentes no BD\n",
    "\"\"\"\n",
    "if Download_BD_Atualizacao == 1:\n",
    "    dict_log_datas = Gerenciador.ler_log()\n",
    "        \n",
    "    lista_anos, result_set = Crawler.carregar_Anos_Consulta()\n",
    "\n",
    "    #Crio arquivo responsável pelo log\n",
    "    dict_log_datas_novo = Crawler.criar_Relacao_Datas_Atualizacao(dict_log_datas)\n",
    "    \n",
    "    #Menor ano do novo dicionário de log\n",
    "    ano = min(dict_log_datas_novo.keys()).year\n",
    "    print(\"Carregando páginas do ano \", str(ano), \"\\n\")    \n",
    "    \n",
    "    \n",
    "    \"\"\"CRAWLER\"\"\"    \n",
    "    #i) Carrego a url pertinente\n",
    "    url = Crawler.carregar_Href_Ano(str(ano), result_set)\n",
    "    \n",
    "    #ii)Capturo as urls dos arquivos deste ano\n",
    "    lista_arquivos = Crawler.carregar_Href_datas(url)\n",
    "    \n",
    "    \"\"\"GERENCIADOR\"\"\"    \n",
    "    #iv)Mapeio os arquivos\n",
    "    print(\"Mapeando arquivos para o ano \", str(ano), \"\\n\")\n",
    "    dict_arquivos_disponiveis = Gerenciador.mapeamento_Arquivos(lista_arquivos, ano)\n",
    "\n",
    "    #v)Faço o download dos arquivos no diretório temporárop\n",
    "    print(\"Iniciando downloads...\", \"\\n\")\n",
    "    Gerenciador.limpar_Diretorio()\n",
    "    dict_log_datas_novo = Gerenciador.download_Arquivos(dict_log_datas_novo, dict_arquivos_disponiveis, ano)\n",
    "    \n",
    "    Gerenciador.atualizar_log(dict_log_datas, dict_log_datas_novo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df190c0",
   "metadata": {},
   "source": [
    "#### ii. Consolidação dos Dados Historicos em um Novo Df_Bilhetagem <font color='red'>(Df_Bilhetagem será sobrescrito) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Criando DF vazio\"\"\"\n",
    "Df_Bilhetagem = Consolidador.criar_Df_Bilhetagem()\n",
    "\n",
    "\"\"\"Listando arquivos temporários\"\"\"\n",
    "arquivos_temp = Consolidador.listar_Arquivos()\n",
    "\n",
    "arquivos_erro = []\n",
    "\"\"\"Recuperando arquivos na lista e fazendo o append à vazia\"\"\"\n",
    "for arquivo in arquivos_temp:    \n",
    "    carregamento, df_temp = Consolidador.carregar_Arquivo(arquivo)    \n",
    "    if carregamento == True:\n",
    "        Df_Bilhetagem = pd.concat([Df_Bilhetagem, df_temp], axis=0, ignore_index=False)\n",
    "    else:\n",
    "        arquivos_erro.append(arquivo)\n",
    "        print(\"Erro ao carregar \", str(arquivo))\n",
    "        \n",
    "if len(arquivos_erro) >0:\n",
    "    print(\"Existem  \", str(len(arquivos_erro)), \" arquivos para serem corrigidos antes de prosseguir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b589736",
   "metadata": {},
   "source": [
    "#### Para caso de Erros (Corrija a coluna A dos arquivos temporários que deram erro (Tabular com Texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd25aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(arquivos_erro) > 0:\n",
    "    \"\"\"Recuperando arquivos na lista e fazendo o append à vazia\"\"\"\n",
    "    for arquivo in arquivos_erro:    \n",
    "        carregamento, df_temp = Consolidador.carregar_Arquivo(arquivo)    \n",
    "        if carregamento == True:\n",
    "            Df_Bilhetagem = pd.concat([Df_Bilhetagem, df_temp], axis=0, ignore_index=False)\n",
    "        else:\n",
    "            print(\"Erro ao carregar \", str(arquivo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1173ce3",
   "metadata": {},
   "source": [
    "#### Totalização e Salvamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Totalização dos Dados        \n",
    "cols_total = ['PASSAGEIROS_GRATUIDADE', 'PASSAGEIROS_GRATUIDADE_ESTUDANTE', 'PASSAGEIROS_PAGANTES', 'PASSAGEIROS_PAGANTES_BU_COMUM', 'PASSAGEIROS_PAGANTES_BU_COMUM_MENSAL', 'PASSAGEIROS_PAGANTES_BU_ESTUDANTES', 'PASSAGEIROS_PAGANTES_BU_ESTUDANTES_MENSAL', 'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP', 'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP_MENSAL', 'PASSAGEIROS_PAGANTES_DINHEIRO', 'PASSAGEIROS_PAGANTES_ESTUDANTES', 'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_METRO_CPTM', 'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_ONIBUS']\n",
    "Df_Bilhetagem['TOTAL'] = Df_Bilhetagem[cols_total].sum(axis=1)\n",
    "\n",
    "#Salvar o Arquivo\n",
    "Df_Bilhetagem.to_csv(diretorio + '/BD_Bilhetagem.csv', encoding='latin-1', index=False)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774321c",
   "metadata": {},
   "source": [
    "## Dados Históricos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97584c93",
   "metadata": {},
   "source": [
    "#### ii. Download dos Dados Historicos  <font color='red'>(Todos os arquivos temporários serão excluídos)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6200b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Para o caso de gerar uma \n",
    "nova extração histórica\n",
    "\"\"\"\n",
    "if Download_BD_Historico == 1:\n",
    "    lista_anos, result_set = Crawler.carregar_Anos_Consulta()\n",
    "\n",
    "    #Os anos de 2014 e 2013 estão em páginas separadas, então faço o append separadamente\n",
    "    lista_anos.append(2014)\n",
    "    lista_anos.append(2013)\n",
    "\n",
    "    #Crio arquivo responsável pelo log\n",
    "    dict_log_datas = Crawler.criar_Relacao_Datas(lista_anos)\n",
    "    \n",
    "    Gerenciador.limpar_Diretorio()\n",
    "\n",
    "    #Para cada ano...\n",
    "    for ano in lista_anos:\n",
    "##    if ano == 2024 and ano != 2023:\n",
    "        print(\"Carregando páginas do ano \", str(ano), \"\\n\")\n",
    "        \"\"\"CRAWLER\"\"\"    \n",
    "        #i) Carrego a url pertinente\n",
    "        url = Crawler.carregar_Href_Ano(str(ano), result_set)\n",
    "        #print(url)\n",
    "\n",
    "        #ii)Capturo as urls dos arquivos deste ano\n",
    "        lista_arquivos = Crawler.carregar_Href_datas(url)\n",
    "\n",
    "        \"\"\"GERENCIADOR\"\"\"\n",
    "        #iv)Mapeio os arquivos\n",
    "        print(\"Mapeando arquivos para o ano \", str(ano), \"\\n\")\n",
    "        dict_arquivos_disponiveis = Gerenciador.mapeamento_Arquivos(lista_arquivos, ano)\n",
    "\n",
    "        #v)Faço o download dos arquivos no diretório temporárop\n",
    "        print(\"Iniciando downloads...\", \"\\n\")\n",
    "        dict_log_datas = Gerenciador.download_Arquivos(dict_log_datas, dict_arquivos_disponiveis, ano)\n",
    "\n",
    "    Gerenciador.salvar_log(dict_log_datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3975e138",
   "metadata": {},
   "source": [
    "#### ii. Consolidação dos Dados Historicos em um Novo Df_Bilhetagem <font color='red'>(Df_Bilhetagem será sobrescrito) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2af3a8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Um banco de dados não pode ser encotrando em C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp\n",
      "Um novo banco de dados está sendo criado para a extração corrente...\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2013_10_13.xls\n",
      "\"['excluir'] not found in axis\"\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2013_10_13.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2013_7_13.xls\n",
      "\"['excluir'] not found in axis\"\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2013_7_13.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2015_3_15.xls\n",
      "\"['excluir'] not found in axis\"\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2015_3_15.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2015_4_15.xls\n",
      "\"['excluir'] not found in axis\"\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2015_4_15.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2015_7_15.xls\n",
      "\"['excluir'] not found in axis\"\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2015_7_15.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2016_10_16.xls\n",
      "\"['excluir'] not found in axis\"\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2016_10_16.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2016_1_16.xls\n",
      "\"['excluir'] not found in axis\"\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2016_1_16.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2016_3_16.xls\n",
      "\"['excluir'] not found in axis\"\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2016_3_16.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2016_5_16.xls\n",
      "\"['excluir'] not found in axis\"\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2016_5_16.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2016_6_16.xls\n",
      "\"['excluir'] not found in axis\"\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2016_6_16.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2016_7_16.xls\n",
      "\"['excluir'] not found in axis\"\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2016_7_16.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2016_8_16.xls\n",
      "\"['excluir'] not found in axis\"\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2016_8_16.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_10_15.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_10_15.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_11_10.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_11_10.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_11_12.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_11_12.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_12_3.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_12_3.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_5_21.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_5_21.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_5_26.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_5_26.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_6_1.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_6_1.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_6_20.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_6_20.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_6_6.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_6_6.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_6_7.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_6_7.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_6_8.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_6_8.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_7_21.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_7_21.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_8_23.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_8_23.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_8_24.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_8_24.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_9_1.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_9_1.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_9_14.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_9_14.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_9_22.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2018_9_22.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_10_28.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_10_28.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_11_8.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_11_8.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_11_9.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_11_9.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_12_16.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_12_16.xls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_12_30.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_12_30.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_1_19.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_1_19.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_1_31.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_1_31.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_2_20.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_2_20.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_2_21.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_2_21.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_2_5.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_2_5.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_2_9.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_2_9.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_3_17.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_3_17.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_5_16.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_5_16.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_5_26.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_5_26.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_6_11.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_6_11.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_6_16.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_6_16.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_6_4.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_6_4.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_7_1.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_7_1.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_7_16.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_7_16.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_7_7.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_7_7.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_8_6.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_8_6.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_9_29.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2019_9_29.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_10_27.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_10_27.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_11_7.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_11_7.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_1_11.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_1_11.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_1_25.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_1_25.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_1_9.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_1_9.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_2_24.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_2_24.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_7_2.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_7_2.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_8_2.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_8_2.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_9_14.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_9_14.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_9_19.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_9_19.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_9_2.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2020_9_2.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2021_2_10.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2021_2_10.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2021_2_2.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2021_2_2.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2022_11_29.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2022_11_29.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2022_11_7.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2022_11_7.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2022_7_5.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2022_7_5.xls\n",
      "ERRO! Não foi possível carregar arquivo C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2023_5_29.xls\n",
      "\n",
      "Erro ao carregar  C:\\Users\\f112596\\Desktop\\Projetos\\DO\\Lab Transp/temp_downloads\\Bilhetagem_2023_5_29.xls\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Criando DF vazio\"\"\"\n",
    "Df_Bilhetagem = Consolidador.criar_Df_Bilhetagem()\n",
    "\n",
    "\"\"\"Listando arquivos temporários\"\"\"\n",
    "arquivos_temp = Consolidador.listar_Arquivos()\n",
    "\n",
    "\n",
    "arquivos_erro = []\n",
    "\"\"\"Recuperando arquivos na lista e fazendo o append à vazia\"\"\"\n",
    "for arquivo in arquivos_temp:    \n",
    "    carregamento, df_temp = Consolidador.carregar_Arquivo(arquivo)    \n",
    "    if carregamento == True:\n",
    "        Df_Bilhetagem = pd.concat([Df_Bilhetagem, df_temp], axis=0, ignore_index=False)\n",
    "    else:\n",
    "        print(\"Erro ao carregar \", str(arquivo))\n",
    "        \n",
    "if len(arquivos_erro) >0:\n",
    "    print(\"Existem  \", str(len(arquivos_erro)), \" arquivos para serem corrigidos antes de prosseguir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b32c7",
   "metadata": {},
   "source": [
    "#### Para caso de Erros (Corrija a coluna A dos arquivos temporários que deram erro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ec42eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(arquivos_erro) > 0:\n",
    "    \"\"\"Recuperando arquivos na lista e fazendo o append à vazia\"\"\"\n",
    "    for arquivo in arquivos_erro:    \n",
    "        carregamento, df_temp = Consolidador.carregar_Arquivo(arquivo)    \n",
    "        if carregamento == True:\n",
    "            Df_Bilhetagem = pd.concat([Df_Bilhetagem, df_temp], axis=0, ignore_index=False)\n",
    "        else:\n",
    "            print(\"Erro ao carregar \", str(arquivo))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b2799c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arquivos_erro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7714e",
   "metadata": {},
   "source": [
    "#### Totalização e Salvamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "948bc367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Totalização dos Dados        \n",
    "cols_total = ['PASSAGEIROS_GRATUIDADE', 'PASSAGEIROS_GRATUIDADE_ESTUDANTE', 'PASSAGEIROS_PAGANTES', 'PASSAGEIROS_PAGANTES_BU_COMUM', 'PASSAGEIROS_PAGANTES_BU_COMUM_MENSAL', 'PASSAGEIROS_PAGANTES_BU_ESTUDANTES', 'PASSAGEIROS_PAGANTES_BU_ESTUDANTES_MENSAL', 'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP', 'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP_MENSAL', 'PASSAGEIROS_PAGANTES_DINHEIRO', 'PASSAGEIROS_PAGANTES_ESTUDANTES', 'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_METRO_CPTM', 'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_ONIBUS']\n",
    "Df_Bilhetagem['TOTAL'] = Df_Bilhetagem[cols_total].sum(axis=1)\n",
    "\n",
    "#Salvar o Arquivo\n",
    "Df_Bilhetagem.to_csv(diretorio + '/BD_Bilhetagem.csv', encoding='latin-1', index=False)        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "68e1f373",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88600329",
   "metadata": {},
   "source": [
    "# Visualização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f8c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if 'Df_Bilhetagem' not in locals() or Df_Bilhetagem==None:\n",
    "        consolidador = consolidador_Arquivos()\n",
    "        Df_Bilhetagem = consolidador.criar_Df_Bilhetagem()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a5c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tratamento do Campo DATA\n",
    "Df_Bilhetagem['DATA'] = Df_Bilhetagem['DATA'].astype(str)\n",
    "Df_Bilhetagem['DATA'] = Df_Bilhetagem['DATA'].str.replace(\" 00:00:00\",\"\")\n",
    "Df_Bilhetagem['DATA'] = pd.to_datetime(Df_Bilhetagem['DATA'], format=\"%Y-%m-%d\")\n",
    "Df_Bilhetagem['ANO'] = pd.DatetimeIndex(Df_Bilhetagem['DATA']).year\n",
    "Df_Bilhetagem['MES'] = pd.DatetimeIndex(Df_Bilhetagem['DATA']).month\n",
    "Df_Bilhetagem['DIA'] = pd.DatetimeIndex(Df_Bilhetagem['DATA']).day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4411feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupamento por Ano/Mês/Linha\n",
    "Df_AnoMesLinha = Df_Bilhetagem[['ANO', 'MES', 'LINHA', 'PASSAGEIROS_GRATUIDADE', 'PASSAGEIROS_GRATUIDADE_ESTUDANTE',\n",
    "                                'PASSAGEIROS_PAGANTES', 'PASSAGEIROS_PAGANTES_BU_COMUM',\n",
    "                                'PASSAGEIROS_PAGANTES_BU_COMUM_MENSAL',\n",
    "                                'PASSAGEIROS_PAGANTES_BU_ESTUDANTES',\n",
    "                                'PASSAGEIROS_PAGANTES_BU_ESTUDANTES_MENSAL',\n",
    "                                'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP',\n",
    "                                'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP_MENSAL',\n",
    "                                'PASSAGEIROS_PAGANTES_DINHEIRO', 'PASSAGEIROS_PAGANTES_ESTUDANTES',\n",
    "                                'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_METRO_CPTM',\n",
    "                                'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_ONIBUS', 'TOTAL']].groupby(as_index=False, by=['ANO', 'MES', 'LINHA']).sum()\n",
    "Df_AnoMesLinha.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589195bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupamento por Ano/Linha\n",
    "Df_AnoLinha = Df_Bilhetagem[['ANO', 'LINHA', 'PASSAGEIROS_GRATUIDADE', 'PASSAGEIROS_GRATUIDADE_ESTUDANTE',\n",
    "                             'PASSAGEIROS_PAGANTES', 'PASSAGEIROS_PAGANTES_BU_COMUM',\n",
    "                             'PASSAGEIROS_PAGANTES_BU_COMUM_MENSAL',\n",
    "                             'PASSAGEIROS_PAGANTES_BU_ESTUDANTES',\n",
    "                             'PASSAGEIROS_PAGANTES_BU_ESTUDANTES_MENSAL',\n",
    "                             'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP',\n",
    "                             'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP_MENSAL',\n",
    "                             'PASSAGEIROS_PAGANTES_DINHEIRO', 'PASSAGEIROS_PAGANTES_ESTUDANTES',\n",
    "                             'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_METRO_CPTM',\n",
    "                             'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_ONIBUS',\n",
    "                             'TOTAL']].groupby(as_index=False, by=['ANO', 'LINHA']).sum()\n",
    "Df_AnoLinha.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120bf70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupamento por Mês/Linha\n",
    "Df_MesLinha = Df_Bilhetagem[['MES', 'LINHA', 'PASSAGEIROS_GRATUIDADE', 'PASSAGEIROS_GRATUIDADE_ESTUDANTE',\n",
    "                             'PASSAGEIROS_PAGANTES', 'PASSAGEIROS_PAGANTES_BU_COMUM',\n",
    "                             'PASSAGEIROS_PAGANTES_BU_COMUM_MENSAL',\n",
    "                             'PASSAGEIROS_PAGANTES_BU_ESTUDANTES',\n",
    "                             'PASSAGEIROS_PAGANTES_BU_ESTUDANTES_MENSAL',\n",
    "                             'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP',\n",
    "                             'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP_MENSAL',\n",
    "                             'PASSAGEIROS_PAGANTES_DINHEIRO', 'PASSAGEIROS_PAGANTES_ESTUDANTES',\n",
    "                             'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_METRO_CPTM',\n",
    "                             'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_ONIBUS',\n",
    "                             'TOTAL']].groupby(as_index=False, by=['MES', 'LINHA']).sum()\n",
    "Df_MesLinha.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da392aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupamento por Ano/Mês\n",
    "Df_AnoMes = Df_Bilhetagem[['ANO', 'MES', 'PASSAGEIROS_GRATUIDADE', 'PASSAGEIROS_GRATUIDADE_ESTUDANTE',\n",
    "                           'PASSAGEIROS_PAGANTES', 'PASSAGEIROS_PAGANTES_BU_COMUM',\n",
    "                           'PASSAGEIROS_PAGANTES_BU_COMUM_MENSAL',\n",
    "                           'PASSAGEIROS_PAGANTES_BU_ESTUDANTES',\n",
    "                           'PASSAGEIROS_PAGANTES_BU_ESTUDANTES_MENSAL',\n",
    "                           'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP',\n",
    "                           'PASSAGEIROS_PAGANTES_BU_VALE_TRANSP_MENSAL',\n",
    "                           'PASSAGEIROS_PAGANTES_DINHEIRO', 'PASSAGEIROS_PAGANTES_ESTUDANTES',\n",
    "                           'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_METRO_CPTM',\n",
    "                           'PASSAGEIROS_PAGANTES_INTEIRO_INTEGRACAO_ONIBUS',\n",
    "                           'TOTAL']].groupby(as_index=False, by=['ANO', 'MES']).sum()\n",
    "Df_AnoMes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Df_Bilhetagem = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
